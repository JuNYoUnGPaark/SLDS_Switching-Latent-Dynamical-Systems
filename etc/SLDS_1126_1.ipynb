{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1qeOXwbtKhJoCoAdo0keKLUumQZjk_6zd","authorship_tag":"ABX9TyNOKyurdr1BV2GUzlzyKStn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4SxzbvdXoXcI","executionInfo":{"status":"ok","timestamp":1764223575129,"user_tz":-540,"elapsed":281339,"user":{"displayName":"Î∞ïÏ§ÄÏòÅ","userId":"08318675183777163575"}},"outputId":"d655935f-f790-4003-84d0-4e42c01d02fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","Pure Switching Latent Dynamical Systems (SLDS)\n","================================================================================\n","\n","Loading UCI-HAR dataset...\n","train set: 7352 samples, 128 timesteps, 9 channels\n","test set: 2947 samples, 128 timesteps, 9 channels\n","\n","Initializing model...\n","Total parameters: 79,350\n","\n","Starting training...\n","Epoch 10/100 (2.1s) | Train Loss: 0.6438, Train Acc: 0.9438 | Test Acc: 0.9019, Test F1: 0.9030 | Best F1: 0.9213\n","  Mode Usage: M0:17.3% ‚ñá | M1:15.3% ‚ñá | M2: 0.0%  | M3: 0.0%  | M4:33.9% ‚ñá‚ñá‚ñá | M5:33.5% ‚ñá‚ñá‚ñá\n","Epoch 20/100 (2.8s) | Train Loss: 0.3451, Train Acc: 0.9505 | Test Acc: 0.9111, Test F1: 0.9106 | Best F1: 0.9341\n","  Mode Usage: M0:18.4% ‚ñá | M1:15.5% ‚ñá | M2: 0.0%  | M3: 0.0%  | M4:31.8% ‚ñá‚ñá‚ñá | M5:34.3% ‚ñá‚ñá‚ñá\n","Epoch 30/100 (2.1s) | Train Loss: 0.2878, Train Acc: 0.9490 | Test Acc: 0.9298, Test F1: 0.9311 | Best F1: 0.9341\n","  Mode Usage: M0:17.7% ‚ñá | M1:13.2% ‚ñá | M2: 0.0%  | M3: 0.0%  | M4:34.3% ‚ñá‚ñá‚ñá | M5:34.9% ‚ñá‚ñá‚ñá\n","Epoch 40/100 (2.0s) | Train Loss: 0.2241, Train Acc: 0.9554 | Test Acc: 0.9196, Test F1: 0.9209 | Best F1: 0.9341\n","  Mode Usage: M0:17.8% ‚ñá | M1:15.3% ‚ñá | M2: 0.0%  | M3: 0.0%  | M4:32.6% ‚ñá‚ñá‚ñá | M5:34.3% ‚ñá‚ñá‚ñá\n","Epoch 50/100 (2.3s) | Train Loss: 0.1165, Train Acc: 0.9555 | Test Acc: 0.9233, Test F1: 0.9242 | Best F1: 0.9341\n","  Mode Usage: M0:17.7% ‚ñá | M1:15.9% ‚ñá | M2: 0.0%  | M3: 0.0%  | M4:32.0% ‚ñá‚ñá‚ñá | M5:34.4% ‚ñá‚ñá‚ñá\n","Epoch 60/100 (2.1s) | Train Loss: 0.0296, Train Acc: 0.9588 | Test Acc: 0.9260, Test F1: 0.9273 | Best F1: 0.9341\n","  Mode Usage: M0:17.3% ‚ñá | M1:22.5% ‚ñá‚ñá | M2: 0.0%  | M3: 0.0%  | M4:25.9% ‚ñá‚ñá | M5:34.3% ‚ñá‚ñá‚ñá\n","Epoch 70/100 (2.1s) | Train Loss: -0.0152, Train Acc: 0.9661 | Test Acc: 0.9087, Test F1: 0.9092 | Best F1: 0.9341\n","  Mode Usage: M0:17.3% ‚ñá | M1:25.9% ‚ñá‚ñá | M2: 0.0%  | M3: 0.0%  | M4:22.4% ‚ñá‚ñá | M5:34.4% ‚ñá‚ñá‚ñá\n","Epoch 80/100 (2.1s) | Train Loss: -0.0228, Train Acc: 0.9642 | Test Acc: 0.9223, Test F1: 0.9234 | Best F1: 0.9341\n","  Mode Usage: M0:17.4% ‚ñá | M1:27.5% ‚ñá‚ñá | M2: 0.0%  | M3: 0.0%  | M4:20.8% ‚ñá‚ñá | M5:34.3% ‚ñá‚ñá‚ñá\n","Epoch 90/100 (2.1s) | Train Loss: -0.0353, Train Acc: 0.9683 | Test Acc: 0.9172, Test F1: 0.9186 | Best F1: 0.9341\n","  Mode Usage: M0:17.3% ‚ñá | M1:27.6% ‚ñá‚ñá | M2: 0.0%  | M3: 0.0%  | M4:20.6% ‚ñá‚ñá | M5:34.5% ‚ñá‚ñá‚ñá\n","Epoch 100/100 (2.1s) | Train Loss: -0.0316, Train Acc: 0.9672 | Test Acc: 0.9243, Test F1: 0.9257 | Best F1: 0.9341\n","  Mode Usage: M0:17.3% ‚ñá | M1:27.7% ‚ñá‚ñá | M2: 0.0%  | M3: 0.0%  | M4:20.7% ‚ñá‚ñá | M5:34.4% ‚ñá‚ñá‚ñá\n","\n","================================================================================\n","Training completed!\n","Best Test F1-Score: 0.9341\n","Best Test Accuracy: 0.9325\n","================================================================================\n"]}],"source":["\"\"\"\n","Pure Switching Latent Dynamical Systems (SLDS) for UCI-HAR\n","Models activities as switching between multiple latent dynamics modes\n","WITHOUT Attractor-based State Flow components\n","\"\"\"\n","\n","import os\n","import time\n","import torch\n","import random\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n","\n","def set_seed(seed=42):\n","    \"\"\"\n","    ÎûúÎç§ ÏãúÎìúÎ•º Í≥†Ï†ïÌïòÏó¨ Ïã§ÌóòÏùò Ïû¨ÌòÑÏÑ±(Reproducibility)ÏùÑ Î≥¥Ïû•Ìï®\n","    \"\"\"\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)  # Î©ÄÌã∞ GPU ÏÇ¨Ïö© Ïãú\n","\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","\n","    # CuDNN Í≤∞Ï†ïÎ°†Ï†Å Î™®Îìú (ÏÜçÎèÑÎäî ÏïΩÍ∞Ñ ÎäêÎ†§Ïßà Ïàò ÏûàÏßÄÎßå Ïû¨ÌòÑÏÑ± ÌïÑÏàò)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","\n","def seed_worker(worker_id):\n","    worker_seed = torch.initial_seed() % 2**32\n","    np.random.seed(worker_seed)\n","    random.seed(worker_seed)\n","\n","# ============================================================================\n","# UCI-HAR Dataset Loader\n","# ============================================================================\n","\n","class UCIHARDataset(Dataset):\n","    def __init__(self, data_path, split='train'):\n","        base_path = os.path.join(data_path, split, 'Inertial Signals')\n","\n","        signals = []\n","        signal_types = [\n","            'body_acc_x', 'body_acc_y', 'body_acc_z',\n","            'body_gyro_x', 'body_gyro_y', 'body_gyro_z',\n","            'total_acc_x', 'total_acc_y', 'total_acc_z'\n","        ]\n","\n","        for signal_type in signal_types:\n","            filename = f'{signal_type}_{split}.txt'\n","            filepath = os.path.join(base_path, filename)\n","            data = np.loadtxt(filepath)\n","            signals.append(data)\n","\n","        self.X = np.stack(signals, axis=-1)\n","\n","        label_path = os.path.join(data_path, split, f'y_{split}.txt')\n","        self.y = np.loadtxt(label_path).astype(np.int64) - 1\n","\n","        print(f'{split} set: {self.X.shape[0]} samples, {self.X.shape[1]} timesteps, {self.X.shape[2]} channels')\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        return torch.FloatTensor(self.X[idx]), torch.LongTensor([self.y[idx]])[0]\n","\n","\n","# ============================================================================\n","# Switching Dynamics Module\n","# ============================================================================\n","\n","class SwitchingDynamicsModule(nn.Module):\n","    \"\"\"\n","    Models latent dynamics as switching between M different modes\n","    s_{t+1} = F_{z_t}(s_t), where z_t ‚àà {1, ..., M}\n","\n","    Each timestep has a mode assignment z_t learned from data\n","    \"\"\"\n","    def __init__(self, latent_dim, num_modes=6, hidden_dim=128):\n","        super().__init__()\n","        self.latent_dim = latent_dim\n","        self.num_modes = num_modes\n","\n","        # Mode-specific dynamics networks\n","        self.mode_dynamics = nn.ModuleList([\n","            nn.Sequential(\n","                nn.Linear(latent_dim, hidden_dim),\n","                nn.Tanh(),\n","                nn.Linear(hidden_dim, hidden_dim),\n","                nn.Tanh(),\n","                nn.Linear(hidden_dim, latent_dim),\n","                nn.Tanh()\n","            ) for _ in range(num_modes)\n","        ])\n","\n","        # Mode inference network (predicts mode from latent state)\n","        self.mode_predictor = nn.Sequential(\n","            nn.Linear(latent_dim, hidden_dim),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(hidden_dim, num_modes)\n","        )\n","\n","    def forward(self, s_sequence):\n","        \"\"\"\n","        Args:\n","            s_sequence: (B, T, D) sequence of latent states\n","        Returns:\n","            s_evolved: (B, T, D) evolved states\n","            mode_probs: (B, T, M) mode probabilities\n","            mode_assignments: (B, T) hard mode assignments\n","        \"\"\"\n","        batch_size, seq_len, _ = s_sequence.shape\n","\n","        # Predict mode probabilities for each timestep\n","        mode_logits = self.mode_predictor(s_sequence)  # (B, T, M)\n","        mode_probs = F.softmax(mode_logits, dim=-1)\n","        mode_assignments = mode_probs.argmax(dim=-1)  # (B, T)\n","\n","        # Apply mode-specific dynamics using soft assignment\n","        s_evolved = torch.zeros_like(s_sequence)\n","\n","        for m in range(self.num_modes):\n","            # Compute dynamics for mode m\n","            s_flat = s_sequence.reshape(-1, self.latent_dim)  # (B*T, D)\n","            delta_m = self.mode_dynamics[m](s_flat)  # (B*T, D)\n","            delta_m = delta_m.reshape(batch_size, seq_len, self.latent_dim)  # (B, T, D)\n","\n","            # Weight by mode probability\n","            mode_weight = mode_probs[:, :, m:m+1]  # (B, T, 1)\n","            s_evolved = s_evolved + mode_weight * (s_sequence + delta_m)\n","\n","        return s_evolved, mode_probs, mode_assignments\n","\n","    def compute_mode_consistency_loss(self, mode_probs):\n","        \"\"\"\n","        Encourage smooth mode transitions (adjacent timesteps similar modes)\n","        \"\"\"\n","        # (B, T, M) -> (B, T-1, M)\n","        mode_diff = mode_probs[:, 1:, :] - mode_probs[:, :-1, :]\n","        consistency_loss = (mode_diff ** 2).mean()\n","        return consistency_loss\n","\n","    def compute_mode_diversity_loss(self, mode_assignments):\n","        \"\"\"\n","        Encourage using all available modes (avoid mode collapse)\n","        \"\"\"\n","        # Count mode usage\n","        mode_counts = torch.zeros(self.num_modes, device=mode_assignments.device)\n","        for m in range(self.num_modes):\n","            mode_counts[m] = (mode_assignments == m).float().sum()\n","\n","        # Normalize to get frequency\n","        mode_freq = mode_counts / (mode_assignments.numel() + 1e-8)\n","\n","        # Diversity loss: maximize entropy\n","        entropy = -(mode_freq * torch.log(mode_freq + 1e-8)).sum()\n","        diversity_loss = -entropy  # Minimize negative entropy = maximize entropy\n","\n","        return diversity_loss\n","\n","\n","# ============================================================================\n","# Main Model\n","# ============================================================================\n","\n","class SLDS_HAR(nn.Module):\n","    \"\"\"\n","    Pure Switching Latent Dynamical Systems for HAR\n","    \"\"\"\n","    def __init__(self, input_dim=9, num_classes=6, num_modes=6, latent_dim=32, hidden_dim=64):\n","        super().__init__()\n","        self.num_modes = num_modes\n","        self.num_classes = num_classes\n","\n","        # Temporal encoder\n","        self.encoder = nn.Sequential(\n","            nn.Conv1d(input_dim, 32, kernel_size=5, padding=2),\n","            nn.BatchNorm1d(32),\n","            nn.ReLU(),\n","            nn.Conv1d(32, 64, kernel_size=5, padding=2),\n","            nn.BatchNorm1d(64),\n","            nn.ReLU(),\n","            nn.Conv1d(64, latent_dim, kernel_size=5, padding=2),\n","            nn.BatchNorm1d(latent_dim),\n","            nn.ReLU()\n","        )\n","\n","        # Switching dynamics\n","        self.switching_dynamics = SwitchingDynamicsModule(latent_dim, num_modes, hidden_dim)\n","\n","        # Temporal pooling\n","        self.temporal_pool = nn.AdaptiveAvgPool1d(1)\n","\n","        # Classifier\n","        self.classifier = nn.Sequential(\n","            nn.Linear(latent_dim, 64),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(64, 32),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(32, num_classes)\n","        )\n","\n","        # Mode-to-class auxiliary classifier\n","        self.mode_class_predictor = nn.Linear(num_modes, num_classes)\n","\n","    def forward(self, x, return_switching_info=False):\n","        \"\"\"\n","        Args:\n","            x: (B, T, C) input time series\n","            return_switching_info: whether to return switching losses and info\n","        \"\"\"\n","        batch_size = x.size(0)\n","\n","        # Encode: (B, T, C) -> (B, C, T) -> (B, D, T)\n","        x = x.transpose(1, 2)\n","        latent_seq = self.encoder(x)  # (B, D, T)\n","        latent_seq = latent_seq.transpose(1, 2)  # (B, T, D)\n","\n","        # Apply switching dynamics\n","        latent_evolved, mode_probs, mode_assignments = self.switching_dynamics(latent_seq)\n","\n","        # Global average pooling\n","        latent_evolved = latent_evolved.transpose(1, 2)  # (B, D, T)\n","        latent_pooled = self.temporal_pool(latent_evolved).squeeze(-1)  # (B, D)\n","\n","        # Classification\n","        logits = self.classifier(latent_pooled)\n","\n","        # Switching information\n","        if return_switching_info:\n","            switching_info = {}\n","\n","            # Mode consistency loss\n","            consistency_loss = self.switching_dynamics.compute_mode_consistency_loss(mode_probs)\n","            switching_info['consistency'] = consistency_loss\n","\n","            # Mode diversity loss\n","            diversity_loss = self.switching_dynamics.compute_mode_diversity_loss(mode_assignments)\n","            switching_info['diversity'] = diversity_loss\n","\n","            # Mode-class alignment\n","            mode_avg = mode_probs.mean(dim=1)  # (B, M)\n","            mode_class_logits = self.mode_class_predictor(mode_avg)\n","            switching_info['mode_class_logits'] = mode_class_logits\n","\n","            return logits, switching_info, mode_assignments\n","        else:\n","            return logits, mode_assignments\n","\n","\n","# ============================================================================\n","# Training & Evaluation\n","# ============================================================================\n","\n","def train_epoch(model, train_loader, optimizer, device, lambda_cons, lambda_div, lambda_align=0.0):\n","    model.train()\n","    total_loss = 0\n","    all_preds, all_labels = [], []\n","\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        # Get predictions and switching information\n","        logits, switching_info, mode_assignments = model(data, return_switching_info=True)\n","\n","        # Classification loss\n","        ce_loss = F.cross_entropy(logits, target)\n","\n","        # Switching dynamics losses\n","        consistency_loss = switching_info['consistency']\n","        diversity_loss = switching_info['diversity']\n","\n","        # Mode-class alignment loss\n","        mode_class_logits = switching_info['mode_class_logits']\n","        alignment_loss = F.cross_entropy(mode_class_logits, target)\n","\n","        # Total loss\n","        loss = ce_loss + lambda_cons * consistency_loss + lambda_div * diversity_loss + lambda_align * alignment_loss\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","        preds = logits.argmax(dim=1)\n","        all_preds.extend(preds.cpu().numpy())\n","        all_labels.extend(target.cpu().numpy())\n","\n","    acc = accuracy_score(all_labels, all_preds)\n","    return total_loss / len(train_loader), acc\n","\n","def evaluate(model, test_loader, device):\n","    model.eval()\n","    all_preds, all_labels = [], []\n","    all_mode_assignments = []\n","\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            logits, mode_assignments = model(data, return_switching_info=False)\n","            preds = logits.argmax(dim=1)\n","\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(target.cpu().numpy())\n","            all_mode_assignments.append(mode_assignments.cpu().numpy())\n","\n","    acc = accuracy_score(all_labels, all_preds)\n","    f1 = f1_score(all_labels, all_preds, average='macro')\n","    cm = confusion_matrix(all_labels, all_preds)\n","\n","    # Analyze mode usage\n","    all_mode_assignments = np.concatenate(all_mode_assignments, axis=0)  # (N, T)\n","    mode_usage = []\n","    for m in range(model.num_modes):\n","        usage = (all_mode_assignments == m).sum() / all_mode_assignments.size\n","        mode_usage.append(usage)\n","\n","    return acc, f1, cm, mode_usage\n","\n","\n","# ============================================================================\n","# Main Execution\n","# ============================================================================\n","\n","def main():\n","    set_seed(42)\n","    g = torch.Generator()\n","    g.manual_seed(42)\n","\n","    # Configuration\n","    data_path = '/content/drive/MyDrive/Colab Notebooks/HAR_data/UCI_HAR'\n","    batch_size = 64\n","    num_epochs = 100\n","    learning_rate = 0.001\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    # Loss weights\n","    lambda_cons = 24.5372   # Mode consistency\n","    lambda_div = 0.4464   # Mode diversity\n","    lambda_align = 1.3725   # Mode-class alignment\n","\n","    print('=' * 80)\n","    print('Pure Switching Latent Dynamical Systems (SLDS)')\n","    print('=' * 80)\n","\n","    # Load datasets\n","    print('\\nLoading UCI-HAR dataset...')\n","    train_dataset = UCIHARDataset(data_path, split='train')\n","    test_dataset = UCIHARDataset(data_path, split='test')\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n","                              num_workers=2, worker_init_fn=seed_worker, generator=g)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n","                             num_workers=2, worker_init_fn=seed_worker, generator=g)\n","\n","    # Model\n","    print('\\nInitializing model...')\n","    model = SLDS_HAR(\n","        input_dim=9,\n","        num_classes=6,\n","        num_modes=6,  # Use 6 modes (same as num_classes)\n","        latent_dim=32,\n","        hidden_dim=64\n","    ).to(device)\n","\n","    print(f'Total parameters: {sum(p.numel() for p in model.parameters()):,}')\n","\n","    # Optimizer\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n","\n","    # Training loop\n","    print('\\nStarting training...')\n","    best_acc = 0\n","    best_f1 = 0\n","\n","    for epoch in range(num_epochs):\n","        start_time = time.time()\n","\n","        train_loss, train_acc = train_epoch(model, train_loader, optimizer, device,\n","                                           lambda_cons, lambda_div, lambda_align)\n","        test_acc, test_f1, cm, mode_usage = evaluate(model, test_loader, device)\n","\n","        scheduler.step()\n","\n","        epoch_time = time.time() - start_time\n","\n","        if test_f1 > best_f1:\n","            best_f1 = test_f1\n","            best_acc = test_acc # Í∏∞Î°ùÏö©ÏúºÎ°ú Í∞ôÏù¥ ÏóÖÎç∞Ïù¥Ìä∏\n","            torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/best_slds_pure.pth')\n","\n","        if (epoch + 1) % 10 == 0:\n","            mode_str = ' | '.join([\n","                f'M{i}:{mode_usage[i]:5.1%} {\"‚ñá\" * int(mode_usage[i] * 10)}'\n","                for i in range(len(mode_usage))\n","            ])\n","            print(f'Epoch {epoch+1}/{num_epochs} ({epoch_time:.1f}s) | '\n","                  f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | '\n","                  f'Test Acc: {test_acc:.4f}, Test F1: {test_f1:.4f} | '\n","                  f'Best F1: {best_f1:.4f}')\n","            print(f'  Mode Usage: {mode_str}')\n","\n","    print('\\n' + '=' * 80)\n","    print(f'Training completed!')\n","    print(f'Best Test F1-Score: {best_f1:.4f}')\n","    print(f'Best Test Accuracy: {best_acc:.4f}')\n","    print('=' * 80)\n","\n","\n","if __name__ == '__main__':\n","    main()"]},{"cell_type":"code","source":["!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CCcVhBNJEsZ1","executionInfo":{"status":"ok","timestamp":1764223623053,"user_tz":-540,"elapsed":5964,"user":{"displayName":"Î∞ïÏ§ÄÏòÅ","userId":"08318675183777163575"}},"outputId":"483dfb27-9833-4b5d-bf00-818ffd990538"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n","Downloading optuna-4.6.0-py3-none-any.whl (404 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n","Installing collected packages: colorlog, optuna\n","Successfully installed colorlog-6.10.1 optuna-4.6.0\n"]}]},{"cell_type":"code","source":["import optuna\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","import numpy as np\n","import random\n","import os\n","\n","# =============================================================================\n","# [Ï§ëÏöî] Í∏∞Ï°¥ ÏΩîÎìú(slds_1126.py)ÏóêÏÑú ÌïÑÏöîÌïú ÏöîÏÜå Í∞ÄÏ†∏Ïò§Í∏∞\n","# =============================================================================\n","# ÎßåÏïΩ slds_1126.pyÍ∞Ä ÏóÜÎã§Î©¥, Í∏∞Ï°¥ ÏΩîÎìúÏùò ClassÏôÄ Ìï®ÏàòÎì§ÏùÑ Ïó¨Í∏∞Ïóê Î≥µÏÇ¨Ìï¥ ÎÑ£ÏúºÏÑ∏Ïöî.\n","try:\n","    from slds_1126 import UCIHARDataset, SLDS_HAR, train_epoch, evaluate, set_seed, seed_worker\n","except ImportError:\n","    # Colab Îì±ÏóêÏÑú ÌååÏùº importÍ∞Ä Ïïà Îê† Í≤ΩÏö∞Î•º ÎåÄÎπÑÌï¥,\n","    # Í∏∞Ï°¥ slds_1126.pyÏùò ÎÇ¥Ïö©ÏùÑ Ïù¥ ÏÖÄ ÏúÑÏóê Î®ºÏ†Ä Ïã§ÌñâÌï¥ÎëêÏãúÎ©¥ Îê©ÎãàÎã§.\n","    pass\n","\n","# =============================================================================\n","# 1. ÌôòÍ≤Ω ÏÑ§Ï†ï\n","# =============================================================================\n","DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/HAR_data/UCI_HAR'  # Í≤ΩÎ°ú ÌôïÏù∏ ÌïÑÏàò!\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","BATCH_SIZE = 64\n","N_TRIALS = 50       # Ïã§Ìóò ÌöüÏàò (ÎßéÏùÑÏàòÎ°ù Ï¢ãÏùå)\n","N_EPOCHS = 100       # Îπ†Î•∏ ÌÉêÏÉâÏùÑ ÏúÑÌï¥ 30 EpochÎßå ÏàòÌñâ (Ï∂©Î∂ÑÌï®)\n","\n","# =============================================================================\n","# 2. Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎìú (Îß§Î≤à Î°úÎìúÌïòÎ©¥ ÎäêÎ¶¨ÎØÄÎ°ú Î∞ñÏóêÏÑú Ìïú Î≤àÎßå Î°úÎìú)\n","# =============================================================================\n","print(\"Loading Data for Optuna...\")\n","set_seed(42)\n","g = torch.Generator()\n","g.manual_seed(42)\n","\n","# Îç∞Ïù¥ÌÑ∞ÏÖã Í∞ùÏ≤¥ ÏÉùÏÑ±\n","full_train_dataset = UCIHARDataset(DATA_PATH, split='train')\n","test_dataset = UCIHARDataset(DATA_PATH, split='test')\n","\n","# Îπ†Î•∏ ÌÉêÏÉâÏùÑ ÏúÑÌï¥ DataLoader ÏÑ§Ï†ï\n","train_loader = DataLoader(full_train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n","                          num_workers=2, worker_init_fn=seed_worker, generator=g)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n","                         num_workers=2, worker_init_fn=seed_worker, generator=g)\n","\n","# =============================================================================\n","# 3. Objective Function (OptunaÍ∞Ä Î∞òÎ≥µ Ïã§ÌñâÌï† Ìï®Ïàò)\n","# =============================================================================\n","def objective(trial):\n","    # -----------------------------------------------------------\n","    # [A] ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÌÉêÏÉâ Î≤îÏúÑ ÏÑ§Ï†ï (Raw Values)\n","    # -----------------------------------------------------------\n","    # Ïä§ÏºÄÏùºÎßÅ ÏóÜÏù¥ Raw Í∞í ÏûêÏ≤¥Î•º ÌÉêÏÉâÌïòÎØÄÎ°ú Î≤îÏúÑÎ•º ÎÑìÍ≤å Ïû°Ïùå\n","\n","    # Consistency: Í∞íÏù¥ ÏûëÏúºÎØÄÎ°ú(0.005) ÌÅ∞ Í∞ÄÏ§ëÏπòÍ∞Ä ÌïÑÏöîÌï† Í≤ÉÏûÑ (1 ~ 50)\n","    lambda_cons = trial.suggest_float(\"lambda_cons\", 1.0, 50.0, log=True)\n","\n","    # Diversity: Í∞íÏù¥ ÌÅ¨ÎØÄÎ°ú(1.8) ÏûëÏùÄ Í∞ÄÏ§ëÏπòÍ∞Ä ÌïÑÏöîÌï† Í≤ÉÏûÑ (0.01 ~ 2.0)\n","    lambda_div  = trial.suggest_float(\"lambda_div\",  0.01, 2.0, log=True)\n","\n","    # Alignment: Í∞íÏù¥ Ï†ÅÎãπÌïòÎØÄÎ°ú(0.5) Ï§ëÍ∞Ñ Í∞ÄÏ§ëÏπò (0.1 ~ 5.0)\n","    lambda_align = trial.suggest_float(\"lambda_align\", 0.1, 5.0, log=True)\n","\n","    # (ÏÑ†ÌÉù) Optimizer ÌååÎùºÎØ∏ÌÑ∞ÎèÑ Í∞ôÏù¥ Ï∞æÍ∏∞\n","    lr = 0.001\n","    weight_decay = 1e-4  # Í∏∞Ï°¥ Ïú†ÏßÄ (ÎòêÎäî trial.suggest_floatÎ°ú ÌÉêÏÉâ Í∞ÄÎä•)\n","\n","    # -----------------------------------------------------------\n","    # [B] Î™®Îç∏ Ï¥àÍ∏∞Ìôî (79k Îã§Ïù¥Ïñ¥Ìä∏ Î≤ÑÏ†Ñ Ïú†ÏßÄ)\n","    # -----------------------------------------------------------\n","    # Í∏∞Ï°¥ ÏΩîÎìú Î°úÏßÅ Í∑∏ÎåÄÎ°ú ÏÇ¨Ïö©\n","    model = SLDS_HAR(\n","        input_dim=9,\n","        num_classes=6,\n","        num_modes=6,\n","        latent_dim=32,   # Îã§Ïù¥Ïñ¥Ìä∏ ÏÑ§Ï†ï\n","        hidden_dim=64    # Îã§Ïù¥Ïñ¥Ìä∏ ÏÑ§Ï†ï\n","    ).to(DEVICE)\n","\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","\n","    # -----------------------------------------------------------\n","    # [C] ÌïôÏäµ Î£®ÌîÑ\n","    # -----------------------------------------------------------\n","    best_f1 = 0.0\n","\n","    for epoch in range(N_EPOCHS):\n","        # 1. ÌïôÏäµ (Í∏∞Ï°¥ train_epoch Ìï®Ïàò Í∑∏ÎåÄÎ°ú ÏÇ¨Ïö©)\n","        # ÎÇ¥Î∂Ä Ïä§ÏºÄÏùºÎßÅ ÏóÜÏù¥ Ï†úÏïàÎêú ÎûåÎã§Í∞í Í∑∏ÎåÄÎ°ú Ï†ÑÎã¨\n","        train_loss, train_acc = train_epoch(\n","            model, train_loader, optimizer, DEVICE,\n","            lambda_cons, lambda_div, lambda_align\n","        )\n","\n","        # 2. ÌèâÍ∞Ä\n","        test_acc, test_f1, cm, mode_usage = evaluate(model, test_loader, DEVICE)\n","\n","        # 3. OptunaÏóêÍ≤å ÌòÑÏû¨ Ï†êÏàò Î≥¥Í≥† (PruningÏö©)\n","        trial.report(test_f1, epoch)\n","\n","        # 4. Í∞ÄÎßù ÏóÜÎäî Ï°∞Ìï©Ïù¥Î©¥ Ï°∞Í∏∞ Ï¢ÖÎ£å (Pruning)\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","        # ÏµúÍ≥† Í∏∞Î°ù Í∞±Ïã†\n","        if test_f1 > best_f1:\n","            best_f1 = test_f1\n","\n","    # ÏµúÏ¢ÖÏ†ÅÏúºÎ°ú Îã¨ÏÑ±Ìïú ÏµúÍ≥† F1 Score Î∞òÌôò\n","    return best_f1\n","\n","# =============================================================================\n","# 4. Ïã§Ìñâ Î∞è Í≤∞Í≥º Ï∂úÎ†•\n","# =============================================================================\n","if __name__ == '__main__':\n","    print(\"üöÄ Starting Optuna Search...\")\n","\n","    # Pruner ÏÑ§Ï†ï: Ï¥àÎ∞òÏóê ÏÑ±Îä• Ïïà ÎÇòÏò§Î©¥ Í≥ºÍ∞êÌûà ÏûêÎ•¥Îäî MedianPruner ÏÇ¨Ïö©\n","    study = optuna.create_study(\n","        direction=\"maximize\",\n","        pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=10)\n","    )\n","\n","    study.optimize(objective, n_trials=N_TRIALS)\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"‚úÖ Best Trial Found!\")\n","    print(\"=\"*50)\n","    best_trial = study.best_trial\n","    print(f\"  Best Test F1: {best_trial.value:.4f}\")\n","    print(\"  Best Hyperparameters:\")\n","    for key, value in best_trial.params.items():\n","        print(f\"    {key}: {value:.4f}\")\n","    print(\"=\"*50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6sv0Fop2EiWp","outputId":"bfefda4c-2cac-4b4c-f328-2c21568dcb4f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading Data for Optuna...\n","train set: 7352 samples, 128 timesteps, 9 channels\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-11-27 06:07:08,135] A new study created in memory with name: no-name-66f2379e-d4cf-4dce-9c57-080f915e455c\n"]},{"output_type":"stream","name":"stdout","text":["test set: 2947 samples, 128 timesteps, 9 channels\n","üöÄ Starting Optuna Search...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-11-27 06:11:05,661] Trial 0 finished with value: 0.940805242108183 and parameters: {'lambda_cons': 2.883311908282027, 'lambda_div': 0.6229026976867933, 'lambda_align': 0.9459837938565204}. Best is trial 0 with value: 0.940805242108183.\n","[I 2025-11-27 06:14:52,022] Trial 1 finished with value: 0.9429915473955891 and parameters: {'lambda_cons': 45.985480977595714, 'lambda_div': 0.027676631238870597, 'lambda_align': 1.3802188496828414}. Best is trial 1 with value: 0.9429915473955891.\n","[I 2025-11-27 06:18:39,657] Trial 2 finished with value: 0.9439602651423399 and parameters: {'lambda_cons': 4.423884007910408, 'lambda_div': 1.015890857337884, 'lambda_align': 3.759506295645196}. Best is trial 2 with value: 0.9439602651423399.\n","[I 2025-11-27 06:22:30,340] Trial 3 finished with value: 0.9426129021510145 and parameters: {'lambda_cons': 7.903639726656165, 'lambda_div': 0.031178223428636118, 'lambda_align': 3.773764833942858}. Best is trial 2 with value: 0.9439602651423399.\n","[I 2025-11-27 06:26:18,295] Trial 4 finished with value: 0.940478869537544 and parameters: {'lambda_cons': 9.939743338405165, 'lambda_div': 0.0431690396127357, 'lambda_align': 1.2731667134903142}. Best is trial 2 with value: 0.9439602651423399.\n","[I 2025-11-27 06:30:05,004] Trial 5 finished with value: 0.9493025689674889 and parameters: {'lambda_cons': 7.600893683219672, 'lambda_div': 0.04722403818748982, 'lambda_align': 1.7325447076728768}. Best is trial 5 with value: 0.9493025689674889.\n","[I 2025-11-27 06:33:50,616] Trial 6 finished with value: 0.942754641521654 and parameters: {'lambda_cons': 10.28487448683226, 'lambda_div': 1.4230036143307658, 'lambda_align': 4.4443638074786715}. Best is trial 5 with value: 0.9493025689674889.\n","[I 2025-11-27 06:37:37,165] Trial 7 finished with value: 0.9482128812446139 and parameters: {'lambda_cons': 1.2544114514102176, 'lambda_div': 0.04633926075924347, 'lambda_align': 1.7506022370385015}. Best is trial 5 with value: 0.9493025689674889.\n","[I 2025-11-27 06:39:11,962] Trial 8 pruned. \n","[I 2025-11-27 06:42:57,012] Trial 9 finished with value: 0.9460692039704295 and parameters: {'lambda_cons': 23.31394971843832, 'lambda_div': 0.2762148170649174, 'lambda_align': 0.11478364518849817}. Best is trial 5 with value: 0.9493025689674889.\n","[I 2025-11-27 06:43:31,034] Trial 10 pruned. \n","[I 2025-11-27 06:47:18,377] Trial 11 finished with value: 0.943965207220729 and parameters: {'lambda_cons': 1.1468886093037234, 'lambda_div': 0.14365380333031794, 'lambda_align': 1.9003566118482345}. Best is trial 5 with value: 0.9493025689674889.\n","[I 2025-11-27 06:47:52,071] Trial 12 pruned. \n","[I 2025-11-27 06:48:17,366] Trial 13 pruned. \n","[I 2025-11-27 06:52:04,175] Trial 14 finished with value: 0.9415376694398955 and parameters: {'lambda_cons': 1.8780623104867635, 'lambda_div': 0.0835806407963423, 'lambda_align': 0.6051816642691598}. Best is trial 5 with value: 0.9493025689674889.\n","[I 2025-11-27 06:55:26,552] Trial 15 pruned. \n","[I 2025-11-27 06:58:45,818] Trial 16 pruned. \n","[I 2025-11-27 06:59:19,454] Trial 17 pruned. \n","[I 2025-11-27 07:03:02,488] Trial 18 finished with value: 0.9403195099561618 and parameters: {'lambda_cons': 1.7603884970785324, 'lambda_div': 0.21481874767360823, 'lambda_align': 1.419507280052164}. Best is trial 5 with value: 0.9493025689674889.\n","[I 2025-11-27 07:06:21,143] Trial 19 pruned. \n","[I 2025-11-27 07:10:04,324] Trial 20 finished with value: 0.9405713135106623 and parameters: {'lambda_cons': 28.919666798194065, 'lambda_div': 0.043711597154262455, 'lambda_align': 1.028622662539437}. Best is trial 5 with value: 0.9493025689674889.\n","[I 2025-11-27 07:13:48,307] Trial 21 finished with value: 0.9405064995202417 and parameters: {'lambda_cons': 18.79724619492693, 'lambda_div': 0.35960852793293585, 'lambda_align': 0.12755581047542666}. Best is trial 5 with value: 0.9493025689674889.\n","[I 2025-11-27 07:14:12,383] Trial 22 pruned. \n","[I 2025-11-27 07:14:43,684] Trial 23 pruned. \n","[I 2025-11-27 07:18:01,350] Trial 24 pruned. \n","[I 2025-11-27 07:21:42,434] Trial 25 finished with value: 0.9423138521370603 and parameters: {'lambda_cons': 3.2767637289468046, 'lambda_div': 0.09141851938746377, 'lambda_align': 1.9139188126241578}. Best is trial 5 with value: 0.9493025689674889.\n","[I 2025-11-27 07:25:22,754] Trial 26 finished with value: 0.9410750905292905 and parameters: {'lambda_cons': 6.471198973193201, 'lambda_div': 0.17778331451084642, 'lambda_align': 2.665078682880111}. Best is trial 5 with value: 0.9493025689674889.\n","[I 2025-11-27 07:29:05,429] Trial 27 finished with value: 0.9353765942890657 and parameters: {'lambda_cons': 11.214936277252514, 'lambda_div': 0.3669047068519354, 'lambda_align': 1.6495179014283088}. Best is trial 5 with value: 0.9493025689674889.\n","[I 2025-11-27 07:32:51,002] Trial 28 finished with value: 0.9467418052445344 and parameters: {'lambda_cons': 1.3992311759804488, 'lambda_div': 0.04189279312958955, 'lambda_align': 0.6949168163745665}. Best is trial 5 with value: 0.9493025689674889.\n","[I 2025-11-27 07:36:33,800] Trial 29 finished with value: 0.9421478664726006 and parameters: {'lambda_cons': 1.3453688255395022, 'lambda_div': 0.018093831498266412, 'lambda_align': 1.0020404860855074}. Best is trial 5 with value: 0.9493025689674889.\n"]}]}]}